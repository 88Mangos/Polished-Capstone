{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split original datasets into train and test\n",
    "\n",
    "each image is RGB, 64 by 64.\n",
    "Training datasets:\n",
    "1. ISIC \n",
    "2. ISIC + DiDI\n",
    "3. ISIC + ArGI\n",
    "\n",
    "Testing Dataset:\n",
    "ISIC + DiDI\n",
    "Exclude ArGI because these images are not guaranteed to be real\n",
    "\n",
    "80% of ISIC will be used in training\n",
    "80% of DiDI will be used in training\n",
    "80% of ArGI will be used in training\n",
    "20% of ISIC will go to testing\n",
    "20% of DiDI will go to testing\n",
    "\n",
    "Data Sources:\n",
    "ISIC: N = 1972\n",
    "DiDI: N = 656\n",
    "ArGI: N = 656\n",
    "\n",
    "80/20 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "CWD = os.getcwd()\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import image\n",
    "from tensorflow.image import ResizeMethod\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CWD)\n",
    "\n",
    "# output path\n",
    "NEW = CWD + \"/newdatasets\"\n",
    "print(NEW)\n",
    "\n",
    "# Path for abbrev: ISIC\n",
    "ISIC = CWD + \"/datasets/ISIC\"\n",
    "print(ISIC)\n",
    "\n",
    "# Path for abbrev: DiDI\n",
    "DIDI = CWD + \"/datasets/DiDI\"\n",
    "print(DIDI)\n",
    "\n",
    "# Path for abbrev: AGI\n",
    "ARGI = CWD + \"/datasets/ArGI\"\n",
    "print(ARGI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing\n",
    "Create function to store the right images\n",
    "\n",
    "1. Create ISIC_Train and ISIC_Test\n",
    "2. Export ISIC_Train to .h5\n",
    "3. Create DiDI_Train and DiDI_Test\n",
    "4. Combine ISIC_Train and DiDI_Train\n",
    "5. Export ISIC_DiDI_Train\n",
    "6. Combine ISIC_Test and DiDI_Test\n",
    "7. Export ISIC_DiDI_Test\n",
    "8. Create ArGI_Train\n",
    "9. Combine ISIC_Train and ArGI_Train\n",
    "10. Export ISIC_ArGI_Train\n",
    "\n",
    "Output .h5 files only contain two cols: images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split(images, labels):\n",
    "    n = len(images)\n",
    "    n_test = round(0.2*n)\n",
    "    n_train = round(0.8*n)\n",
    "    if not (n_train == n - n_test):\n",
    "        return ValueError\n",
    "    \n",
    "    test_idx, train_idx = 0,0\n",
    "    test = np.empty(shape=[n_test, 64, 64, 3], dtype=np.uint8)\n",
    "    train = np.empty(shape=[n_train, 64, 64, 3], dtype=np.uint8)\n",
    "    test_labels = np.empty(shape=[n_test, 1])\n",
    "    train_labels = np.empty(shape=[n_train ,1])\n",
    "    \n",
    "    test_indices = random.sample(range(n),n_test)\n",
    "    for i in range(n):\n",
    "        if i in test_indices:\n",
    "            test[test_idx] = images[i]\n",
    "            test_labels[test_idx] = labels[i]\n",
    "            test_idx += 1\n",
    "        else:\n",
    "            train[train_idx] = images[i]\n",
    "            train_labels[train_idx] = labels[i]\n",
    "            train_idx += 1\n",
    "        \n",
    "    if not (len(test) == len(test_labels) == n_test):\n",
    "        return ValueError\n",
    "\n",
    "    if not (len(train) == len(train_labels) == n_train):\n",
    "        return ValueError\n",
    "    \n",
    "    return train, train_labels, test, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dataset, abbrev):\n",
    "    metadata = pd.read_excel(f'{dataset}/metadata_{abbrev}.xlsx', index_col = 'index')\n",
    "    num_imgs = len(metadata['id'])\n",
    "    labels = np.array(metadata['malignance'], dtype=np.uint8).reshape(num_imgs, 1)\n",
    "    images = np.empty(shape=[num_imgs, 64, 64, 3], dtype=np.uint8)\n",
    "    for i in range(num_imgs):\n",
    "        id = metadata['id'][i]\n",
    "        #image = tf.keras.utils.load_img(f'{dataset}/all_images/{id}', target_size = (64, 64))\n",
    "        #image =- cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.imread(f'{dataset}/all_images/{id}')\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        images[i] = image\n",
    "    \n",
    "    if not (len(images) == len(labels) == num_imgs):\n",
    "        return ValueError\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ISIC, labels_ISIC = load(ISIC, \"ISIC\")\n",
    "train_ISIC, train_labels_ISIC, test_ISIC, test_labels_ISIC = split(images_ISIC, labels_ISIC)\n",
    "print(len(train_ISIC))\n",
    "print(len(train_labels_ISIC))\n",
    "print(len(test_ISIC))\n",
    "print(len(test_labels_ISIC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_DIDI, labels_DIDI = load(DIDI, \"DiDI\")\n",
    "train_DIDI, train_labels_DIDI, test_DIDI, test_labels_DIDI = split(images_DIDI, labels_DIDI)\n",
    "print(len(train_DIDI))\n",
    "print(len(train_labels_DIDI))\n",
    "print(len(test_DIDI))\n",
    "print(len(test_labels_DIDI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ArGI, labels_ArGI = load(ARGI, \"ArGI\")\n",
    "train_ArGI, train_labels_ArGI, _, _ = split(images_ArGI, labels_ArGI)\n",
    "print(len(train_ArGI))\n",
    "print(len(train_labels_ArGI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(images, labels, filename):\n",
    "    with h5py.File(f'{CWD}/datasets/split/{filename}.h5','w') as f:\n",
    "        f.create_dataset('images', data = images)\n",
    "        f.create_dataset('labels', data = labels)\n",
    "\n",
    "\n",
    "# \"\"\" Execute on Exports\n",
    "# Processing\n",
    "# Create function to store the right images\n",
    "\n",
    "# 1. Create ISIC_Train and ISIC_Test\n",
    "# 2. Export ISIC_Train to .h5\n",
    "# 3. Create DiDI_Train and DiDI_Test\n",
    "# 4. Combine ISIC_Train and DiDI_Train\n",
    "# 5. Export ISIC_DiDI_Train\n",
    "# 6. Combine ISIC_Test and DiDI_Test\n",
    "# 7. Export ISIC_DiDI_Test\n",
    "# 8. Create ArGI_Train\n",
    "# 9. Combine ISIC_Train and ArGI_Train\n",
    "# 10. Export ISIC_ArGI_Train\n",
    "\n",
    "# Output .h5 files only contain two cols: images and labels\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging to create compound datasets\n",
    "\n",
    "train_ISIC_DiDI = np.append(train_ISIC, train_DIDI, axis=0)\n",
    "train_labels_ISIC_DiDI = np.append(train_labels_ISIC, train_labels_DIDI)\n",
    "train_labels_ISIC_DiDI = np.reshape(train_labels_ISIC_DiDI, [len(train_ISIC_DiDI), 1])\n",
    "if len(train_ISIC_DiDI) == len(train_labels_ISIC_DiDI):\n",
    "    print(len(train_ISIC_DiDI)) \n",
    "    print(train_labels_ISIC_DiDI.shape)\n",
    "\n",
    "test_ISIC_DiDI = np.append(test_ISIC, test_DIDI, axis=0)\n",
    "test_labels_ISIC_DiDI = np.append(test_labels_ISIC, test_labels_DIDI)\n",
    "test_labels_ISIC_DiDI = np.reshape(test_labels_ISIC_DiDI, [len(test_ISIC_DiDI), 1])\n",
    "if len(test_ISIC_DiDI) == len(test_labels_ISIC_DiDI):\n",
    "    print(len(test_ISIC_DiDI)) \n",
    "    print(test_labels_ISIC_DiDI.shape)\n",
    "\n",
    "train_ISIC_ArGI = np.append(train_ISIC, train_ArGI, axis=0)\n",
    "train_labels_ISIC_ArGI = np.append(train_labels_ISIC, train_labels_ArGI)\n",
    "train_labels_ISIC_ArGI = np.reshape(train_labels_ISIC_ArGI, [len(train_ISIC_ArGI), 1])\n",
    "if len(train_ISIC_ArGI) == len(train_labels_ISIC_ArGI):\n",
    "    print(len(train_ISIC_ArGI)) \n",
    "    print(train_labels_ISIC_ArGI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export(train_ISIC, train_labels_ISIC, 'train_ISIC')\n",
    "export(train_ISIC_DiDI, train_labels_ISIC_DiDI, 'train_ISIC_DiDI')\n",
    "export(train_ISIC_ArGI, train_labels_ISIC_ArGI, 'train_ISIC_ArGI')\n",
    "export(test_ISIC_DiDI, test_labels_ISIC_DiDI, 'test_ISIC_DiDI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
