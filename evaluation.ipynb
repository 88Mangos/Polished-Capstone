{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "import h5py\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import functools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "# print(CWD)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions: Load and Visualize Datasets ###\n",
    "\n",
    "### Function: load dataset ###\n",
    "@keras.saving.register_keras_serializable(package='capstone',name='load_dataset')\n",
    "def load_dataset(path_to_training_data):\n",
    "    with h5py.File(path_to_training_data) as f:\n",
    "        # Print the keys (names) of all groups and datasets in the file\n",
    "        print(\"Keys:\", list(f.keys()))\n",
    "\n",
    "        # Iterate through each key and print more detailed information\n",
    "        for key in f.keys():\n",
    "            if isinstance(f[key], h5py.Dataset):\n",
    "                print(f\"Dataset: {key}\")\n",
    "                print(\"  Shape:\", f[key].shape)\n",
    "                print(\"  Data type:\", f[key].dtype)\n",
    "                \n",
    "    ### Instantiate Loader Function ###\n",
    "    return mdl.lab2.TrainingDatasetLoader(path_to_training_data)\n",
    "\n",
    "### Function: visualize dataset ###\n",
    "@keras.saving.register_keras_serializable(package='capstone',name='visualize_dataset')\n",
    "def visualize_dataset(path_to_training_data, loader):\n",
    "    ### Visualize our data ###\n",
    "    number_of_training_examples = loader.get_train_size()\n",
    "    print(number_of_training_examples)\n",
    "    (images, labels) = loader.get_batch(100)\n",
    "    malignant_images = images[np.where(labels==1)[0]]\n",
    "    benign_images = images[np.where(labels==0)[0]]\n",
    "\n",
    "    idx_malignant = 23\n",
    "    idx_benign = 9\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(malignant_images[idx_malignant])\n",
    "    plt.title(\"Malignant\"); plt.grid(False)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(benign_images[idx_benign])\n",
    "    plt.title(\"Benign\"); plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions: Model Definitions ###\n",
    "\n",
    "### Standard CNN ###\n",
    "\n",
    "# Helper Functions\n",
    "\n",
    "@keras.saving.register_keras_serializable(package='capstone', name='resize_images')\n",
    "def resize_images(x):\n",
    "    return tf.image.resize(x, (64, 64))\n",
    "\n",
    "# CNN Function\n",
    "@keras.saving.register_keras_serializable(package='capstone', name='make_standard_ResNet50_V2')\n",
    "def make_standard_ResNet50_V2(n_outputs = 1):\n",
    "    \n",
    "    Resize = tf.keras.layers.Lambda(resize_images)\n",
    "    Flatten = tf.keras.layers.Flatten\n",
    "    Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
    "    ResNet50V2 = tf.keras.applications.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\", # Utilizing Transfer Learning, also maintains consistency\n",
    "        input_tensor=None,\n",
    "        input_shape=(64,64,3),\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        classifier_activation=\"softmax\",\n",
    "    )\n",
    "    ResNet50V2 = tf.keras.Model(inputs = ResNet50V2.layers[1].input, \n",
    "                                outputs = ResNet50V2.layers[-1].output)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(Resize)\n",
    "    model.add(ResNet50V2)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Dense(n_outputs, activation=None))\n",
    "\n",
    "    return model\n",
    "\n",
    "### DB-VAE ###\n",
    "\n",
    "### Define Decoder Network ###\n",
    "@keras.saving.register_keras_serializable(package='capstone', name='make_decoder_network')\n",
    "def make_decoder_network(latent_dim = 100, n_filters = 12 ):\n",
    "    \"\"\"\n",
    "    Layer Types, Functional Definition\n",
    "    \"\"\"\n",
    "    Conv2DTranspose = functools.partial(tf.keras.layers.Conv2DTranspose, padding='same', activation='relu')\n",
    "    Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
    "    Reshape = tf.keras.layers.Reshape \n",
    "    BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "    LeakyReLU = tf.keras.layers.LeakyReLU\n",
    "    # Decoder\n",
    "    decoder = tf.keras.Sequential([\n",
    "        Dense(units=4*4*6*n_filters),\n",
    "        Reshape(target_shape=(4,4,6*n_filters)),\n",
    "\n",
    "        Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return decoder\n",
    "\n",
    "### DB_VAE Helper Functions ###\n",
    "\n",
    "\n",
    "### VAE Reparameterization ###\n",
    "@keras.saving.register_keras_serializable(package='capstone', name='sampling_VAE_reparameterization')\n",
    "def sampling(z_mean, z_logsigma):\n",
    "    batch, latent_dim = z_mean.shape\n",
    "    epsilon = tf.random.normal(shape=(batch, latent_dim))\n",
    "    z = z_mean + tf.math.exp(0.5 * z_logsigma) * epsilon\n",
    "    return z\n",
    "\n",
    "### Defining the VAE loss function ###\n",
    "@keras.saving.register_keras_serializable(package='capstone', name='vae_loss_function')\n",
    "def vae_loss_function(x, x_recon, mu, logsigma, kl_weight=0.0005):\n",
    "  latent_loss = 0.5 * tf.reduce_sum(tf.exp(logsigma) + tf.square(mu) - 1.0 - logsigma, axis=1)\n",
    "  reconstruction_loss = tf.reduce_mean(tf.abs(x-x_recon), axis=(1,2,3))\n",
    "  vae_loss = kl_weight * latent_loss + reconstruction_loss\n",
    "  return vae_loss\n",
    "\n",
    "### Loss function for DB-VAE ###\n",
    "@keras.saving.register_keras_serializable(package='capstone',name='debiasing_loss_function')\n",
    "def debiasing_loss_function(x, x_pred, y, y_logit, mu, logsigma):\n",
    "  vae_loss = vae_loss_function(x, x_pred, mu, logsigma)\n",
    "  classification_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=y_logit)\n",
    "  malignance_indicator = tf.cast(tf.equal(y, 1), tf.float32)\n",
    "  total_loss = tf.reduce_mean(\n",
    "      classification_loss +\n",
    "      malignance_indicator * vae_loss\n",
    "  )\n",
    "  return total_loss, classification_loss\n",
    "\n",
    "### Defining and creating the DB-VAE ###\n",
    "@keras.saving.register_keras_serializable(package='capstone')\n",
    "class DB_VAE(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(DB_VAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "\n",
    "    # Define the number of outputs for the encoder. Recall that we have\n",
    "    # `latent_dim` latent variables, as well as a supervised output for the\n",
    "    # classification.\n",
    "    num_encoder_dims = 2*self.latent_dim + 1\n",
    "\n",
    "    self.encoder = make_standard_ResNet50_V2(num_encoder_dims)\n",
    "    self.decoder = make_decoder_network()\n",
    "\n",
    "  def encode(self, x):\n",
    "    encoder_output = self.encoder(x)\n",
    "    y_logit = tf.expand_dims(encoder_output[:, 0], -1)\n",
    "    z_mean = encoder_output[:, 1:self.latent_dim+1]\n",
    "    z_logsigma = encoder_output[:, self.latent_dim+1:]\n",
    "\n",
    "    return y_logit, z_mean, z_logsigma\n",
    "\n",
    "  def reparameterize(self, z_mean, z_logsigma):\n",
    "    z = sampling(z_mean, z_logsigma)\n",
    "    return z\n",
    "\n",
    "  def decode(self, z):\n",
    "    reconstruction = self.decoder(z)\n",
    "    return reconstruction\n",
    "\n",
    "  def call(self, x):\n",
    "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
    "    z = self.reparameterize(z_mean, z_logsigma)\n",
    "    recon = self.decode(z)\n",
    "    return y_logit, z_mean, z_logsigma, recon\n",
    "\n",
    "  def predict(self, x):\n",
    "    y_logit, z_mean, z_logsigma = self.encode(x)\n",
    "    return y_logit\n",
    "  \n",
    "### DB_VAE Training Helper Functions ###\n",
    "\n",
    "# Function to return the means for an input image batch\n",
    "@keras.saving.register_keras_serializable(package='capstone',name='get_latent_mu')\n",
    "def get_latent_mu(images, dbvae, batch_size=1024, latent_dim=100):\n",
    "    N = images.shape[0]\n",
    "    mu = np.zeros((N, latent_dim))\n",
    "    for start_ind in range(0, N, batch_size):\n",
    "        end_ind = min(start_ind+batch_size, N+1)\n",
    "        batch = (images[start_ind:end_ind]).astype(np.float32)/255.\n",
    "        _, batch_mu, _ = dbvae.encode(batch)\n",
    "        mu[start_ind:end_ind] = batch_mu\n",
    "    return mu\n",
    "\n",
    "@keras.saving.register_keras_serializable(package='capstone',name='get_training_sample_probabilities')\n",
    "def get_training_sample_probabilities(images, dbvae, bins=10, smoothing_fac=0.001, latent_dim=100):\n",
    "    print(\"Recomputing the sampling probabilities\")\n",
    "    mu = get_latent_mu(images, dbvae)\n",
    "    training_sample_p = np.zeros(mu.shape[0])\n",
    "    for i in range(latent_dim):\n",
    "        latent_distribution = mu[:,i]\n",
    "        hist_density, bin_edges =  np.histogram(latent_distribution, density=True, bins=bins)\n",
    "        bin_edges[0] = -float('inf')\n",
    "        bin_edges[-1] = float('inf')\n",
    "        bin_idx = np.digitize(latent_distribution, bin_edges)\n",
    "        hist_smoothed_density = hist_density + smoothing_fac\n",
    "        hist_smoothed_density = hist_smoothed_density / np.sum(hist_smoothed_density)\n",
    "        p = 1.0/(hist_smoothed_density[bin_idx-1])\n",
    "        p = p / np.sum(p)\n",
    "        training_sample_p = np.maximum(p, training_sample_p)\n",
    "    training_sample_p /= np.sum(training_sample_p)\n",
    "\n",
    "    return training_sample_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiate Loaders ###\n",
    "loaders = []\n",
    "loader_20_ISIC_DiDI = load_dataset(f'{CWD}/datasets/split-80train-20test/test_ISIC_DiDI.h5')\n",
    "loaders.append(loader_20_ISIC_DiDI)\n",
    "loader_ISIC_DiDI = load_dataset(f'{CWD}/datasets/whole/ISIC_DiDI.h5')\n",
    "loaders.append(loader_ISIC_DiDI)\n",
    "loader_DiDI = load_dataset(f'{CWD}/datasets/DiDI/DiDI.h5')\n",
    "loaders.append(loader_DiDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "### Which models do you want? ###\n",
    "subfolder = '2024-5-30-models_4'\n",
    "year = 2024\n",
    "month = 5\n",
    "day = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    models.append(keras.models.load_model(f'{CWD}/{subfolder}/Model_{i}.keras', safe_mode=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, runs, batch_size, loader_test):\n",
    "    ### Evaluation of model on test dataset (n = 526) ###\n",
    "\n",
    "    ### Confusion Matrices ###\n",
    "    \"\"\"\n",
    "    | TP  FP |\n",
    "    | FN  TN |\n",
    "    where TP is true positive\n",
    "    FP is false positive\n",
    "    FN is false negative\n",
    "    TN is true negative\n",
    "    Precision equals TP / (TP + FP)\n",
    "    Recall equals TP / (FN + TP)\n",
    "    harmonic mean of precision and recall gives F1 score\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    Sensitivity: TP / (FN + TP)\n",
    "\n",
    "    Specificity: TN / (FP + TN)\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    acc = np.empty(shape=[runs])\n",
    "    spec = np.empty(shape=[runs])\n",
    "    sens = np.empty(shape=[runs])\n",
    "    pre = np.empty(shape=[runs])\n",
    "    rec = np.empty(shape=[runs])\n",
    "    f1s = np.empty(shape=[runs])\n",
    "    for i in range(runs):\n",
    "        # print(batch_x.shape) # (256, 64, 64, 3), these are the test images\n",
    "        # print(batch_y.shape) # (256, 1), these are the test labels\n",
    "        (batch_x, batch_y) = loader_test.get_batch(batch_size)\n",
    "\n",
    "        ### Predict on the test batch ###\n",
    "        \"\"\"\n",
    "        returns an EagerTensor when it's a DB-VAE but a numpy array when it's a CNN. \n",
    "        I don't know why.\n",
    "        \"\"\"\n",
    "        \n",
    "        y_pred_standard = tf.round(tf.nn.sigmoid(model.predict(batch_x)))\n",
    "        acc_standard = tf.reduce_mean(tf.cast(tf.equal(batch_y, y_pred_standard), tf.float32))\n",
    "   \n",
    "        cm = confusion_matrix(batch_y, y_pred_standard)\n",
    "\n",
    "        assert batch_size == np.sum(cm)\n",
    "        \n",
    "        tp = cm[0,0]\n",
    "        fp = cm[0,1]\n",
    "        fn = cm[1,0]\n",
    "        tn = cm[1,1]\n",
    "        \n",
    "        accuracy, specificity, sensitivity, precision, recall, f1score = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "        ### Compute Accuracy: TP + FP divided by batch_size ###\n",
    "        if (np.sum(cm) == 0):\n",
    "            accuracy = np.nan\n",
    "        else:\n",
    "            accuracy = float(tp + tn) / float(batch_size)\n",
    "            assert accuracy == acc_standard # sanity check\n",
    "\n",
    "        ### Compute Sensitivity: TP divided by FN + TP ###\n",
    "        ### Sensitivity is the same as Recall ###\n",
    "        if (fn + tp == 0):\n",
    "            sensitivity = np.nan\n",
    "        else:\n",
    "            sensitivity = float(tp) / float(tp + fn)\n",
    "        recall = sensitivity\n",
    "\n",
    "        ### Compute Specificity: TN divided by FP + TN ###\n",
    "        if (tn + fp == 0):\n",
    "            specificity = np.nan\n",
    "        else:\n",
    "            specificity = float(tn) / float(fp + tn)\n",
    "\n",
    "        ### Compute Precision: TP divided by TP + FP ###\n",
    "        if (tp + fp == 0):\n",
    "            precision = np.nan\n",
    "        else:\n",
    "            precision = float(tp) / float(tp + fp)\n",
    "\n",
    "        ### Compute F1-Score: two times the product of precision and recall, divided by the sum of precision and recall ###\n",
    "        ### https://stackoverflow.com/questions/68796138/a-way-around-f1-score-calculation-when-recall-and-precision-is-zero-in-python ###\n",
    "        if (precision + recall == 0 or precision == np.nan or recall == np.nan):\n",
    "            f1score = np.nan\n",
    "        else: \n",
    "            f1score = 2 * precision * recall / float(precision + recall)\n",
    "\n",
    "        # print(cm)\n",
    "        # print(f'accuracy: {accuracy}')\n",
    "        # print(f'specificity: {specificity}')\n",
    "        # print(f'sensitivity: {sensitivity}')\n",
    "        # print(f'precision: {precision}')\n",
    "        # print(f'F1-score: {f1score}')\n",
    "\n",
    "        acc[i] = accuracy\n",
    "        spec[i] = specificity\n",
    "        sens[i] = sensitivity\n",
    "        pre[i] = precision\n",
    "        rec[i] = recall\n",
    "        f1s[i] = f1score    \n",
    "    \n",
    "    return [acc.mean(), spec.mean(), sens.mean(), pre.mean(), rec.mean(), f1s.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty(shape=[3, 6, 6]) # 3 test datasets, 6 models, 6 metrics per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    for j in range(6):\n",
    "        results[i][j] = evaluate(models[j], 30, 256, loaders[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[0]) # test 20-ISIC-DiDI -> Good metric, though there is some overlap so model 2 will perform rlly good and model 5 should do well too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[1]) # test ISIC_DiDI -> good metric, though this really favors model 2 because it is literally Model 2's training dataset all over again, and a simple CNN will obviously do well on its training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[2]) # test DiDI -> decent metric, but unfairly decreases performance of models that aren't 2 and 5 because DDI's format is not the same as ISIC in terms of how the images were collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20_ISIC_DiDI = pd.DataFrame(data=results[0], \n",
    "                                    columns=[\n",
    "                                        'accuracy',\n",
    "                                        'specificity',\n",
    "                                        'sensitivity',\n",
    "                                        'precision',\n",
    "                                        'recall',\n",
    "                                        'f1score',                                             \n",
    "                                             ]\n",
    "                                    )\n",
    "\n",
    "print(results_20_ISIC_DiDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ISIC_DiDI = pd.DataFrame(data=results[1], \n",
    "                                    columns=[\n",
    "                                        'accuracy',\n",
    "                                        'specificity',\n",
    "                                        'sensitivity',\n",
    "                                        'precision',\n",
    "                                        'recall',\n",
    "                                        'f1score',                                             \n",
    "                                             ]\n",
    "                                    )\n",
    "\n",
    "print(results_ISIC_DiDI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DiDI = pd.DataFrame(data=results[2], \n",
    "                                    columns=[\n",
    "                                        'accuracy',\n",
    "                                        'specificity',\n",
    "                                        'sensitivity',\n",
    "                                        'precision',\n",
    "                                        'recall',\n",
    "                                        'f1score',                                             \n",
    "                                             ]\n",
    "                                    )\n",
    "\n",
    "print(results_DiDI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
