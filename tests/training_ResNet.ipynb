{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras import Model, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = # train dir\n",
    "valid_path = # val dir\n",
    "test_path = # test dir\n",
    "filepath = # for output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few things to keep in mind are train, validation, and test data preprocessing and some parameters.\n",
    "\n",
    "\n",
    "num_train_samples = 656  # DDI\n",
    "\n",
    "num_val_samples = 219  # my ISIC validation subset\n",
    "\n",
    "num_test_samples = 607  # my Dermatlas test set\n",
    "\n",
    "train_batch_size = 10\n",
    "\n",
    "val_batch_size = 10\n",
    "\n",
    "test_batch_size = 10\n",
    "\n",
    "image_size = 224  # this is needed for ResNet\n",
    "\n",
    "\n",
    "# Declare how many steps are needed in an iteration\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "test_steps = np.ceil(num_test_samples / test_batch_size)\n",
    "\n",
    "\n",
    "train_batches = ImageDataGenerator(\n",
    "    preprocessing_function=tensorflow.keras.applications.resnet50.preprocess_input\n",
    ").flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=train_batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "\n",
    "valid_batches = ImageDataGenerator(\n",
    "    tensorflow.keras.applications.resnet50.preprocess_input\n",
    ").flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=val_batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "\n",
    "test_batches = ImageDataGenerator(\n",
    "    tensorflow.keras.applications.resnet50.preprocess_input\n",
    ").flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=test_batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# freezing all blocks except the last\n",
    "\n",
    "for layer in base_model.layers[0:143]:\n",
    "\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "for layer in base_model.layers[143:]:\n",
    "\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode=\"max\"\n",
    ")\n",
    "\n",
    "\n",
    "# try early stopping to avoid overfitting\n",
    "\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", mode=\"max\", patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_accuracy\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"max\",\n",
    "    min_lr=0.00001,\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_batches,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=30,  # was 20 but initial 30\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
